import streamlit as st
import requests
import pandas as pd
import time
from datetime import datetime
import io
import re
import altair as alt

st.set_page_config(page_title="HH Vacancies App", layout="wide")

st.title("HH Vacancies Scraper")

# –í–≤–æ–¥ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è –Ω–∞–∑–≤–∞–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏
keywords_input = st.text_area(
    "–í–≤–µ–¥–∏—Ç–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–∏ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é):",
    value="–ø—Ä–æ–¥—É–∫—Ç –º–µ–Ω–µ–¥–∂–µ—Ä,product manager,–ø—Ä–æ–¥–∞–∫—Ç –º–µ–Ω–µ–¥–∂–µ—Ä,–º–µ–Ω–µ–¥–∂–µ—Ä –ø—Ä–æ–¥—É–∫—Ç–∞"
)

# –í–≤–æ–¥ –∏—Å–∫–ª—é—á–∞—é—â–∏—Ö —Å–ª–æ–≤
exclude_input = st.text_area(
    "–í–≤–µ–¥–∏—Ç–µ —Å–ª–æ–≤–∞ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é):",
    value="–ë–ê–î—ã,—Ä–µ—Ü–µ–ø—Ç,–∑–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω,—Ñ–∞—Ä–º,pharm"
)

# –í–≤–æ–¥ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö —Å–ª–æ–≤ –¥–ª—è –æ–ø–∏—Å–∞–Ω–∏—è
desc_include_input = st.text_area(
    "–í–≤–µ–¥–∏—Ç–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–∏ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é):",
    value="–∞–Ω–∞–ª–∏—Ç–∏–∫–∞,data,sql,product,–º–∞—Ä–∫–µ—Ç–∏–Ω–≥"
)

# –í–≤–æ–¥ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —Å–ª–æ–≤ –¥–ª—è –æ–ø–∏—Å–∞–Ω–∏—è
desc_exclude_input = st.text_area(
    "–í–≤–µ–¥–∏—Ç–µ —Å–ª–æ–≤–∞ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–∏ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é):",
    value="–ø—Ä–æ–¥–∞–∂–∏,–æ—Ñ–∏—Ü–∏–∞–Ω—Ç,–∫—É—Ä—å–µ—Ä"
)

# –†–µ–∂–∏–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
match_mode = st.radio(
    "–ö–∞–∫ –ø—Ä–∏–º–µ–Ω—è—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞?",
    ["–•–æ—Ç—è –±—ã –æ–¥–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ", "–í—Å–µ —Å–ª–æ–≤–∞ –¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞—Å—Ç—å"]
)

keywords = [k.strip() for k in keywords_input.split(",") if k.strip()]
exclude_keywords = [k.strip() for k in exclude_input.split(",") if k.strip()]
desc_include_keywords = [k.strip() for k in desc_include_input.split(",") if k.strip()]
desc_exclude_keywords = [k.strip() for k in desc_exclude_input.split(",") if k.strip()]

# API –¥–∞–Ω–Ω—ã–µ
area_id = 160
per_page = 100
url_api = "https://api.hh.kz/vacancies"
city = "–ê–ª–º–∞—Ç—ã"

vacancies = []


def highlight_text(text, words):
    if not text:
        return "-"
    for w in words:
        pattern = re.compile(re.escape(w), re.IGNORECASE)
        text = pattern.sub(
            fr'<span style="background-color: yellow; font-weight: bold;">\g<0></span>',
            text,
        )
    return text


if st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–æ–∏—Å–∫"):

    progress_text = st.empty()

    for keyword in keywords:
        progress_text.text(f"–ü–æ–∏—Å–∫ –ø–æ —Å–ª–æ–≤—É: {keyword}")
        page = 0

        while True:
            params = {"text": keyword, "area": area_id, "per_page": per_page, "page": page}
            headers = {"User-Agent": "Mozilla/5.0"}
            response = requests.get(url_api, params=params, headers=headers)

            if response.status_code != 200:
                st.error(f"–û—à–∏–±–∫–∞ API: {response.status_code}")
                break

            data = response.json()
            items = data.get("items", [])

            if not items:
                break

            for vac in items:
                title = vac.get("name", "")
                descr = vac.get("snippet", {}).get("responsibility", "")

                # –ò—Å–∫–ª—é—á–∞—é—â–∏–µ —Å–ª–æ–≤–∞ –≤ TITLE
                if any(ex.lower() in title.lower() for ex in exclude_keywords):
                    continue

                # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –≤ TITLE
                title_words = title.lower()

                if match_mode == "–í—Å–µ —Å–ª–æ–≤–∞ –¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞—Å—Ç—å":
                    if not all(k.lower() in title_words for k in keywords):
                        continue
                else:
                    if not any(k.lower() in title_words for k in keywords):
                        continue

                # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏—è
                descr_low = descr.lower()

                if any(ex.lower() in descr_low for ex in desc_exclude_keywords):
                    continue

                if desc_include_keywords:
                    if not any(w.lower() in descr_low for w in desc_include_keywords):
                        continue

                # –ü–æ–¥—Å–≤–µ—Ç–∫–∞
                title_highlighted = highlight_text(title, keywords)
                descr_highlighted = highlight_text(descr, desc_include_keywords)

                salary = vac.get("salary")
                addr = vac.get("address")
                address = "-"
                if addr:
                    parts = [addr.get("street", ""), addr.get("building", "")]
                    address = ", ".join([p for p in parts if p]) or "-"

                vacancies.append({
                    "–ù–∞–∑–≤–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏": title_highlighted,
                    "–ö–æ–º–ø–∞–Ω–∏—è": vac.get("employer", {}).get("name", "-"),
                    "–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ": keyword,
                    "–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏": vac.get("published_at", "-")[:10],
                    "–û–ø–∏—Å–∞–Ω–∏–µ": descr_highlighted,
                    "–ê–¥—Ä–µ—Å": address,
                    "–°—Å—ã–ª–∫–∞ HH": vac.get("alternate_url", "-"),
                })

            page += 1
            time.sleep(0.2)

    st.success(f"–ü–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à—ë–Ω. –ù–∞–π–¥–µ–Ω–æ {len(vacancies)} –≤–∞–∫–∞–Ω—Å–∏–π.")

    if vacancies:
        df = pd.DataFrame(vacancies)

        # –í—ã–≤–æ–¥ —Ç–∞–±–ª–∏—Ü—ã
        st.write(df.to_html(escape=False, index=False), unsafe_allow_html=True)

        # üî• –ê–ù–ê–õ–ò–¢–ò–ö–ê: –ß–∞—Å—Ç–æ—Ç–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –Ω–∞–≤—ã–∫–æ–≤
        st.header("–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –Ω–∞–≤—ã–∫–æ–≤")

        skill_freq = {}

        for skill in desc_include_keywords:
            count = sum(skill.lower() in str(desc).lower() for desc in df["–û–ø–∏—Å–∞–Ω–∏–µ"])
            skill_freq[skill] = count

        df_skills = pd.DataFrame({
            "–ù–∞–≤—ã–∫": list(skill_freq.keys()),
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ": list(skill_freq.values())
        })

        chart = (
            alt.Chart(df_skills)
            .mark_bar()
            .encode(
                x="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ:Q",
                y=alt.Y("–ù–∞–≤—ã–∫:N", sort="-x"),
                tooltip=["–ù–∞–≤—ã–∫", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"]
            )
            .properties(height=400)
        )

        st.altair_chart(chart, use_container_width=True)

        # Excel
        excel_buffer = io.BytesIO()
        df.to_excel(excel_buffer, index=False)
        excel_buffer.seek(0)

        st.download_button(
            "–°–∫–∞—á–∞—Ç—å Excel",
            excel_buffer,
            "vacancies.xlsx",
            "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )
