import streamlit as st
import requests
import pandas as pd
import time
from datetime import datetime, timedelta
from io import BytesIO

st.set_page_config(page_title="HH –≤–∞–∫–∞–Ω—Å–∏–∏", layout="wide")
st.title("–ü–æ–∏—Å–∫ –≤–∞–∫–∞–Ω—Å–∏–π –Ω–∞ HH")

# –í–≤–æ–¥ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
keywords_input = st.text_input(
    "–í–≤–µ–¥–∏—Ç–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é):",
    "–ø—Ä–æ–¥—É–∫—Ç –º–µ–Ω–µ–¥–∂–µ—Ä,product manager,–ø—Ä–æ–¥–∞–∫—Ç –º–µ–Ω–µ–¥–∂–µ—Ä,–º–µ–Ω–µ–¥–∂–µ—Ä –ø—Ä–æ–¥—É–∫—Ç–æ–≤,–º–µ–Ω–µ–¥–∂–µ—Ä –ø–æ –ø—Ä–æ–¥—É–∫—Ç–∞–º,–º–µ–Ω–µ–¥–∂–µ—Ä –ø–æ –ø—Ä–æ–¥—É–∫—Ç—É,–º–µ–Ω–µ–¥–∂–µ—Ä –ø—Ä–æ–¥—É–∫—Ç–∞,–ø—Ä–æ–¥—É–∫—Ç–æ–ª–æ–≥,—ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø—Ä–æ–¥—É–∫—Ç—É,–ø—Ä–æ–¥—É–∫—Ç–æ–≤—ã–π —ç–∫—Å–ø–µ—Ä—Ç,–ø—Ä–æ–¥—É–∫—Ç–æ–≤—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä"
)
keywords = [k.strip() for k in keywords_input.split(",") if k.strip()]

# –í–≤–æ–¥ –∏—Å–∫–ª—é—á–∞–µ–º—ã—Ö —Å–ª–æ–≤
exclude_input = st.text_input(
    "–í–≤–µ–¥–∏—Ç–µ –∏—Å–∫–ª—é—á–∞–µ–º—ã–µ —Å–ª–æ–≤–∞ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é):",
    "–ë–ê–î—ã, —Ä–µ—Ü–µ–ø—Ç, –∑–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω"
)
exclude_keywords = [k.strip() for k in exclude_input.split(",") if k.strip()]

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–∏—Å–∫–∞
area_id = 160
per_page = 100
url_api = "https://api.hh.kz/vacancies"
city = "–ê–ª–º–∞—Ç—ã"

# –ö–Ω–æ–ø–∫–∞ –∑–∞–ø—É—Å–∫–∞
if st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–æ–∏—Å–∫"):
    st.info("–ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ –≤–∞–∫–∞–Ω—Å–∏–π...")
    vacancies = []

    for keyword in keywords:
        page = 0
        st.write(f"üîç –ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É: {keyword}")
        while True:
            params = {"text": keyword, "area": area_id, "per_page": per_page, "page": page}
            headers = {"User-Agent": "Mozilla/5.0"}
            try:
                response = requests.get(url_api, params=params, headers=headers, timeout=10)
                data = response.json()
            except:
                st.error("–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ HH API")
                break
            items = data.get("items", [])
            if not items:
                break
            for vac in items:
                title = vac.get("name", "")
                if keyword.lower() in title.lower() and not any(ex.lower() in title.lower() for ex in exclude_keywords):
                    salary = vac.get("salary")
                    addr = vac.get("address")
                    address_parts = []
                    if addr:
                        if addr.get("street"):
                            address_parts.append(addr.get("street"))
                        if addr.get("building"):
                            address_parts.append(addr.get("building"))
                    address = ", ".join(address_parts) if address_parts else "-"

                    vacancies.append({
                        "keyword": keyword,
                        "title": title,
                        "url": vac.get("alternate_url", "-"),
                        "company": vac.get("employer", {}).get("name", "-"),
                        "description": vac.get("snippet", {}).get("responsibility", "-"),
                        "published_at": vac.get("published_at", "-"),
                        "salary_from": salary.get("from", "-") if salary else "-",
                        "salary_to": salary.get("to", "-") if salary else "-",
                        "currency": salary.get("currency", "-") if salary else "-",
                        "address": address
                    })
            page += 1
            time.sleep(0.2)

    if not vacancies:
        st.warning("–í–∞–∫–∞–Ω—Å–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
    else:
        df = pd.DataFrame(vacancies)
        df['published_date'] = pd.to_datetime(df['published_at']).dt.date
        df.sort_values('published_date', ascending=False, inplace=True)

        # HTML —Ç–∞–±–ª–∏—Ü–∞ —Å –ø–æ–¥—Å–≤–µ—Ç–∫–æ–π
        today = datetime.now().date()
        html_content = """
        <style>
        table { border-collapse: collapse; width: 100%; }
        th, td { border: 1px solid #ccc; padding: 8px; text-align: left; }
        th { background-color: #f2f2f2; }
        tr.green { background-color: #d4edda; }  
        tr.blue { background-color: #cce5ff; }   
        tr.yellow { background-color: #fff3cd; } 
        tr.gray { background-color: #e2e3e5; }   
        tr:hover { background-color: #f1f1f1; }
        a { text-decoration: none; color: #1a0dab; }
        </style>
        <table>
        <tr>
        <th>–ù–∞–∑–≤–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏</th>
        <th>–ö–æ–º–ø–∞–Ω–∏—è</th>
        <th>–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ</th>
        <th>–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏</th>
        <th>–ó–∞—Ä–ø–ª–∞—Ç–∞</th>
        <th>–ê–¥—Ä–µ—Å</th>
        </tr>
        """
        for _, row in df.iterrows():
            days_diff = (today - row['published_date']).days
            if days_diff <= 7:
                color_class = "green"
            elif days_diff <= 14:
                color_class = "blue"
            elif days_diff <= 21:
                color_class = "yellow"
            else:
                color_class = "gray"

            salary_text = f"{row['salary_from']} - {row['salary_to']} {row['currency']}" if row['salary_from'] != "-" else "-"

            if row['address'] != "-":
                query = f"{city}, {row['address']}".replace(" ", "+")
                address_link = f"<a href='https://2gis.kz/almaty/search/{query}' target='_blank'>{row['address']}</a>"
            else:
                address_link = "-"

            html_content += f"<tr class='{color_class}'>"
            html_content += f"<td><a href='{row['url']}' target='_blank'>{row['title']}</a></td>"
            html_content += f"<td>{row['company']}</td>"
            html_content += f"<td>{row['keyword']}</td>"
            html_content += f"<td>{row['published_date']}</td>"
            html_content += f"<td>{salary_text}</td>"
            html_content += f"<td>{address_link}</td>"
            html_content += "</tr>"

        html_content += "</table>"
        st.markdown(html_content, unsafe_allow_html=True)
        st.success(f"–ù–∞–π–¥–µ–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(df)}")

        # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è CSV
        csv = df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="–°–∫–∞—á–∞—Ç—å CSV",
            data=csv,
            file_name='hh_vacancies.csv',
            mime='text/csv'
        )
